{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBC: To be confirmed\n",
    "\n",
    "# 0. Inspect data and code\n",
    "\n",
    "1. Check features\n",
    "    - ~~inspect visual features~~\n",
    "    - ~~how they generate the 21 feature maps?~~\n",
    "    - ~~text features~~\n",
    "    - ~~Does it  include feature extraction code?~~\n",
    "    - video metadata\n",
    "    \n",
    "2. Run code\n",
    "    - ~~run test_network.sh~~\n",
    "    - ~~run run_job_rgb.sh~~\n",
    "    \n",
    "3. Batching\n",
    "    - ~~generation~~\n",
    "    \n",
    "4. Text pre-processing\n",
    "    - details\n",
    "\n",
    "## Summary\n",
    "\n",
    "1. Feature description\n",
    "    - RGB and flow features are of size 4096 and 1024, respectively.\n",
    "    - The HDF5 file contains a double tensor of size (6, feat_size)\n",
    "    - TBC: the value on each matrix corresponds to the feature of a 5s chunk.\n",
    "    - Features for each of the 21 possible segments and context features are computed on-the-fly.\n",
    "        - Take a look at L:181:L:197 in file `data_processing.py`\n",
    "            - [URL]()\n",
    "        - Normalization: Frobenius norm of the feature matrix\n",
    "    - Text queries are ...\n",
    "        - There are two features glove matrix and number of words in query.\n",
    "        - Matrix of `[max_len_sentence, num_glove_centroids]`\n",
    "            - Matrix is arrange in a particular way. Order is consistent but short sentences will be padded with a lot of zeros at the begining.\n",
    "        - Number of words is encoded as a vector of size [max_len_sentence]\n",
    "            - This is a binary vector with 1s on the locations where the query has words.\n",
    "\n",
    "2. Minibatch generation\n",
    "    - Given a sampled clip $c_i^p$ from a video $p$ located in interval $i$. Two additional clips $c_j^p, c_i^q$ are sampled randomly such that $j \\neq i, p \\neq q$. In other words, sample a random clip inside the video and sample a clip located in the interval $i$ from a random video in the dataset.\n",
    "        - code detailing data sampling [here](https://github.com/LisaAnne/LocalizingMoments/blob/master/utils/data_processing.py#L348-L407)\n",
    "        - Only a single additional clip from the video is taken randomly is clear [here](https://github.com/LisaAnne/LocalizingMoments/blob/master/utils/data_processing.py#L363-L366)\n",
    "        - Only a single additional clip from other videos is taken randomly is clear [here](https://github.com/LisaAnne/LocalizingMoments/blob/master/utils/data_processing.py#L371-L376)\n",
    "\n",
    "## Questions\n",
    "\n",
    "1. Visaul feature details\n",
    "    1. value on each matrix corresponds to the feature of a 5s chunk. If shorter is the zero vector.\n",
    "    1. feature extraction details\n",
    "    1. Frobenius normalization vs avg pooling\n",
    "1. Loss function\n",
    "    - Discuss about mini-batch generation\n",
    "1. Code details\n",
    "    a. Block of code is repeated in L:43-L45 in `data_processing.py`\n",
    "1. Access to the crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.a inspect visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000\n"
     ]
    }
   ],
   "source": [
    "hola = 1\n",
    "print(f'{hola:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "filename = 'data/average_fc7.h5'\n",
    "fid = h5py.File(filename)\n",
    "keys = list(fid.keys())\n",
    "print('Number of keys in file', len(keys))\n",
    "print('Type of keys', type(fid[keys[0]]))\n",
    "print('Shape of value', fid[keys[0]].shape)\n",
    "print('Type of value', fid[keys[0]].dtype)\n",
    "\n",
    "feat_size = fid[keys[0]].shape\n",
    "for k, v in fid.items():\n",
    "    assert all([j == feat_size[i] for i, j in enumerate(v.shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1.b inspect json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "33005\n",
      "<class 'dict'>\n",
      "Number of keys 6\n",
      "Keys: ['num_segments', 'description', 'dl_link', 'times', 'video', 'annotation_id']\n",
      "a brown rat goes into someone's hand then onto a cage.\n",
      "[[2, 2], [2, 2], [2, 2], [2, 2]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filename = 'data/train_data.json'\n",
    "with open(filename) as f:\n",
    "    data = json.load(f)\n",
    "print(type(data))\n",
    "print(len(data))\n",
    "print(type(data[0]))\n",
    "print('Number of keys', len(data[0]))\n",
    "print('Keys:', list(data[0].keys()))\n",
    "# Simple assertion\n",
    "for i in data:\n",
    "    assert len(i) == len(data[0])\n",
    "print(data[0]['description'])\n",
    "print(data[0]['times'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N. Ideas\n",
    "\n",
    "## Engineering\n",
    "\n",
    "- Feature engineering (ResNet50, ResNet152, InceptionV4)\n",
    "\n",
    "- Batch generation\n",
    "    - Curriculum learning or mining for sampling negative instances\n",
    "    - Add more negative clips in a given video\n",
    "\n",
    "- Add classifier over nouns, adjectives, verbs to improve embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
