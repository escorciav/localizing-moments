{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump results of multiple snapshots\n",
    "\n",
    "- Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "loss = 'lossintra'\n",
    "cue = 'flow'\n",
    "# loss = 'lossinter'\n",
    "# cue = 'flow'\n",
    "\n",
    "prototxts = glob.glob('prototxts/*.prototxt')\n",
    "protobins = sorted(glob.glob('snapshots/*.caffemodel'))\n",
    "\n",
    "def is_model(seed, filename, cue='rgb', loss='lossintra'):\n",
    "    return ('rng' in filename and seed in filename and\n",
    "            loss in filename and cue in filename)\n",
    "\n",
    "def is_prototxt(filename, cue='rgb', loss='lossintra'):\n",
    "    return ('deploy' in filename and 'rng' in filename and\n",
    "            loss in filename and cue in filename)\n",
    "\n",
    "for i in prototxts:\n",
    "    if is_prototxt(i, cue=cue, loss=loss):\n",
    "        seed = i.split('_rng')[1].split('_')[0]\n",
    "        \n",
    "        protobins_i = [j for j in protobins\n",
    "                       if is_model(seed, j, cue=cue, loss=loss)]\n",
    "        if len(protobins_i) < 3:\n",
    "            continue\n",
    "        j = os.path.basename(protobins_i[0]).split('_iter_')[0]        \n",
    "        \n",
    "        !bash assess_flow.sh $i $j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "loss = 'lossintra'\n",
    "cue = 'rgb'\n",
    "# loss = 'lossinter'\n",
    "# cue = 'rgb'\n",
    "\n",
    "prototxts = glob.glob('prototxts/*.prototxt')\n",
    "protobins = sorted(glob.glob('snapshots/*.caffemodel'))\n",
    "\n",
    "def is_model(seed, filename, cue='rgb', loss='lossintra'):\n",
    "    return ('rng' in filename and seed in filename and\n",
    "            loss in filename and cue in filename)\n",
    "\n",
    "def is_prototxt(filename, cue='rgb', loss='lossintra'):\n",
    "    return ('deploy' in filename and 'rng' in filename and\n",
    "            loss in filename and cue in filename)\n",
    "\n",
    "for i in prototxts:\n",
    "    if is_prototxt(i, cue=cue, loss=loss):\n",
    "        seed = i.split('_rng')[1].split('_')[0]\n",
    "        \n",
    "        protobins_i = [j for j in protobins\n",
    "                       if is_model(seed, j, cue=cue, loss=loss)]\n",
    "        if len(protobins_i) < 3:\n",
    "            continue\n",
    "        \n",
    "        j = os.path.basename(protobins_i[0]).split('_iter_')[0]        \n",
    "        !bash assess_rgb.sh $i $j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-check results and prototxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print(len(glob.glob('prototxts/deploy_*_rgb_*_lossinter_*.prototxt')))\n",
    "print(len(glob.glob('results/clip_retrieval_rgb_*_lossinter_*_val.p')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best seed and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rgb', 'lossintra')\n",
      "('Avg: ', array([0.2373445 , 0.74633971, 0.35395362]))\n",
      "('Std: ', array([0.00319618, 0.00351935, 0.00217724]))\n",
      "('Best: ', array([0.23588517, 0.75287081, 0.35795322]))\n",
      "('seed: ', '3779497804', '; iter: ', 30000)\n",
      "\n",
      "('flow', 'lossintra')\n",
      "('Avg: ', array([0.26291866, 0.77370813, 0.38822568]))\n",
      "('Std: ', array([0.005374  , 0.00326527, 0.00586131]))\n",
      "('Best: ', array([0.27272727, 0.77129187, 0.39913477]))\n",
      "('seed: ', '384112814', '; iter: ', 30000)\n",
      "\n",
      "('rgb', 'lossinter')\n",
      "('Avg: ', array([0.11411483, 0.35339713, 0.29859171]))\n",
      "('Std: ', array([0.0091524 , 0.02353921, 0.01084511]))\n",
      "('Best: ', array([0.13636364, 0.40167464, 0.31169192]))\n",
      "('seed: ', '2227967492', '; iter: ', 10000)\n",
      "\n",
      "('flow', 'lossinter')\n",
      "('Avg: ', array([0.14449761, 0.41255981, 0.34805409]))\n",
      "('Std: ', array([0.00566233, 0.01607337, 0.00480636]))\n",
      "('Best: ', array([0.15526316, 0.43899522, 0.3463756 ]))\n",
      "('seed: ', '2227967492', '; iter: ', 20000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "loss = 'lossintra'\n",
    "cue = 'rgb'\n",
    "ind_metric_for_tie = 1\n",
    "\n",
    "\n",
    "def best_along_multiple_columns(x, ind_col_if_tied=1):\n",
    "    votes = np.argmax(x, axis=0)\n",
    "    candidates, counts = np.unique(votes, return_counts=True)\n",
    "    if len(candidates) == x.shape[1]:\n",
    "        return np.argmax(x[:, ind_col_if_tied])\n",
    "    else:\n",
    "        return candidates[np.argsort(counts)[-1]]\n",
    "\n",
    "for (cue, loss) in [('rgb', 'lossintra'),\n",
    "                    ('flow', 'lossintra'),\n",
    "                    ('rgb', 'lossinter'),\n",
    "                    ('flow', 'lossinter')]:\n",
    "    results = glob.glob('results/*{}*rng*{}*.p'\n",
    "                    .format(cue, loss))\n",
    "    \n",
    "    y = []\n",
    "    seed = []\n",
    "    best_iter = []\n",
    "    for i in results:\n",
    "        with open(i, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        # pick best iteration\n",
    "        x = []\n",
    "        iterations = []\n",
    "        for j in data:\n",
    "            if 'performance' in data[j]:\n",
    "                iterations.append(j)\n",
    "                x.append(data[j]['performance'])\n",
    "        x_arr = np.array(x)\n",
    "        ind = best_along_multiple_columns(\n",
    "            x_arr, ind_col_if_tied=ind_metric_for_tie)\n",
    "        y.append(x_arr[ind, :])\n",
    "        best_iter.append(iterations[ind])\n",
    "        seed_i = i.split('rng')[1].split('_')[0]\n",
    "        seed.append(seed_i)\n",
    "\n",
    "    print(cue, loss)\n",
    "    # compute mean and std per metric\n",
    "    y_arr = np.array(y)\n",
    "    print('Avg: ', y_arr.mean(axis=0))\n",
    "    print('Std: ', y_arr.std(axis=0))\n",
    "\n",
    "    # pick best rng\n",
    "    ind = best_along_multiple_columns(\n",
    "        y_arr, ind_col_if_tied=ind_metric_for_tie)\n",
    "    print('Best: ', y_arr[ind, :])\n",
    "    print('seed: ', seed[ind], '; iter: ', best_iter[ind])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double check above procedure is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 30000\n",
    "seed = 384112814\n",
    "cue = 'rgb'\n",
    "cue = 'flow'\n",
    "loss = 'lossintra'\n",
    "loss = 'lossinter'\n",
    "\n",
    "filename = 'results/clip_retrieval_{}_hachiko_rng{}_feature_process_context_recurrent_embedding_lfTrue_dv0.3_dl0.0_nlv2_nlllstm_no_embed_edl1000-100_edv500-100_pmFalse_{}_lwInter1_val.p'\n",
    "data = pickle.load(open(filename.format(cue, seed, loss), 'rb'))\n",
    "data[iteration]['performance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump features\n",
    "\n",
    "manual dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB model on val...\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading glove embedding\n",
      "4170/4180Dumping features\n",
      "Dumped results to: results/queries_val.hdf5\n",
      "Dumped results to: results/corpus_val.hdf5\n",
      "Flow model on val...\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading glove embedding\n",
      "4170/4180Dumping features\n",
      "Dumped results to: results/queries_val_flow.hdf5\n",
      "Dumped results to: results/corpus_val_flow.hdf5\n",
      "RGB model on test...\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading glove embedding\n",
      "4020/4021Dumping features\n",
      "Dumped results to: results/queries_test.hdf5\n",
      "Dumped results to: results/corpus_test.hdf5\n",
      "Flow model on test...\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading glove embedding\n",
      "4020/4021Dumping features\n",
      "Dumped results to: results/queries_test_flow.hdf5\n",
      "Dumped results to: results/corpus_test_flow.hdf5\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "rgb_seed, flow_seed = 2227967492, 2227967492\n",
    "rgb_iter, flow_iter = 10000, 20000\n",
    "loss = 'lossinter'\n",
    "\n",
    "def get_file(wildcard):\n",
    "    files = glob.glob(wildcard)\n",
    "    assert len(files) == 1\n",
    "    return files[0]\n",
    "\n",
    "prototxt_fmt = 'prototxts/deploy_clip_retrieval_clip_retrieval_{}_hachiko_rng{}_feature_process_context_recurrent_embedding_lfTrue_dv0.3_dl0.0_nlv2_nlllstm_no_embed_edl1000-100_edv500-100_pmFalse_{}_*.prototxt'\n",
    "protobin_fmt = 'snapshots/clip_retrieval_{}_hachiko_rng{}_feature_process_context_recurrent_embedding_lfTrue_dv0.3_dl0.0_nlv2_nlllstm_no_embed_edl1000-100_edv500-100_pmFalse_{}_*_iter_{}.caffemodel'\n",
    "rgb_prototxt = get_file(prototxt_fmt.format('rgb', rgb_seed, loss))\n",
    "flow_prototxt = get_file(prototxt_fmt.format('flow', flow_seed, loss))\n",
    "rgb_protobin = get_file(protobin_fmt.format('rgb', rgb_seed, loss, rgb_iter))\n",
    "flow_protobin = get_file(protobin_fmt.format('flow', flow_seed, loss, flow_iter))\n",
    "!bash dump_features.sh $rgb_prototxt $flow_prototxt $rgb_protobin $flow_protobin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
